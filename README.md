# ğŸ” LLM-based RAG Search System (with Memory)

This project combines a **Flask backend** and a **Streamlit frontend** to build a **Retrieval-Augmented Generation (RAG)** application powered by LLMs. It allows users to input queries, fetches relevant web articles using SerpAPI, processes the content, and generates intelligent responses using Groq's LLaMA-3. It also maintains a **memory buffer of the last 5 messages** to retain context across interactions.

---

## ğŸš€ Features

- ğŸ” Searches the web for relevant content using SerpAPI  
- ğŸ“„ Scrapes and cleans article content using BeautifulSoup  
- ğŸ§  Generates contextual responses with Groq's LLaMA-3 model  
- ğŸ—‚ï¸ Maintains a 5-message memory buffer for conversational history  
- ğŸ§ª Streamlit frontend for simple user interaction  
- ğŸŒ Flask-based backend for API processing

---

## ğŸ“¦ Requirements

Install dependencies via:

```bash
pip install -r requirements.txt
